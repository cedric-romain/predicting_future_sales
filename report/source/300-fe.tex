\subsection{Create zero sales}

The training dataset tells us exactly which item got sold when and where. At the same time, this tells us exactly which shop did not sell any given item on a given date.
With this information, we can craft the possibly most important feature of them all: add the records from a possible combination of a given month, all shops and all items and fill the sale record with 0. This operation was dubbed \enquote{create zero sales}.
The mathematical function of this operation can be expressed with the following cartesian product:

\vspace*{-4mm}
$$
\{\text{\texttt{date\_block\_num}}_i\}
\quad \times \quad
\{{\text{\texttt{shop\_id}}}\}
\quad  \times \quad 
\{{\text{\texttt{item\_id}}}\}
\quad \mid \quad
i \cap [0; 33]
$$

This operation was implemented using the Python function \texttt{product} from the \texttt{itertools} package from the Python standard library.\footnote{\href{https://docs.python.org/3/library/itertools.html\#itertools.product}{\texttt{itertools} - official documentation}}

\noindent \textit{N.B. that this ignores the months which have not sold anything in the considered time period.}

\subsection{Shop information}

To add detailed information about the shops, we first identified the city in which a shop is located. To continue from there, we researched geographic and demographic data. This information was added to a spreadsheet and exported as \acrfull{csv} file in a similar manner to the original dataset. The following features have been added: \texttt{zip\_code}, \texttt{region}, \texttt{population}, \texttt{population\_growth} and \texttt{region\_gdp}.

The population growth was considered on a city level from a time frame roughly between 2010--2018. (varying according to different sources from discovered materials)

The population and gdp (per capita) information was primarily taken from the year 2018. Again, this was due to the abundance of information publicly available for this period.

\subsection{Category information}

The process of arranging detailed features for the various categories was definitely more arbitrary compared to the shop information. After translating all 84 categories, some were very specific and hereby intuitive, for instance the category 12 \enquote{Game consoles - PS4}. This could easily be split into a type (\enquote{game console}), a dedicated device (\enquote{ps4}), platform (\enquote{playstation}), manufacturer (\enquote{sony}) and a medium (\enquote{physical}).

The same distinctions were harder to make for other categories like \enquote{Gifts - Stuffed Toys} or \enquote{Service}. These could be interpreted very differently, we attempted to create meaningful splits to our best intentions. This resulted the following new features:
\vspace*{-2mm}
\begin{center}
\texttt{category\_type}, \ \texttt{category\_device}, \ \texttt{category\_device\_for\_platform}, \ \texttt{category\_device\_for\_platform\_manufacturer}, \ \texttt{category\_medium\_type}, \ \texttt{category\_is\_fancy}
\end{center}
The last feature, \texttt{category\_is\_fancy}, evolved from the distinction in certain existing categories like \enquote{PC Games - Standard Editions} and \enquote{PC Games - Collector's Editions} which expects the latter to have a narrower target audience for a same title.

\subsection{Lag features}

\begin{wrapfigure}[8]{l}{0.48\textwidth}
\centering
\input{source/340-lag_feature.tex}
\captionsetup{justification=centering}
\caption{Creating lag features}
\label{lag}
\end{wrapfigure}


In the next step, we have created a set of lag features. The adjoining figure illustrates the procedure how to create them. The idea is that, every label $y_t$ in function of its time $t$, is dependent of its preceeding value $y_{t-n}$ in a time series. $n$ is choosen to suit the time interval of the problem, for instance $n \cap \{1;2;3;6;12\}$ to consider the past two months, trimester, semester and year in a monthly spaced time series. Consequently, the lag$\_n$ series shifts the label for $n$ intervals forward in time. To accomplish this feature for several different existing features, the following function has been implemented:

\lstinputlisting[language=python, caption=Compute Lag Features]{external_content/code/lag_features.py}

The function receives following parameters: main DataFrame (containing all the features), the intervals to be lagged and the features which are lagged. Then, the individual lags are iterated: begin by storing the relevant columns from the DataFrame, add a new column, shift the date one forward and merge the newly created feature back onto the main DataFrame. (\textit{the \texttt{cl} function simply concatenates elements of lists together})


\subsection{Average prices}

Foo

\subsection{Additional features}

Foo
