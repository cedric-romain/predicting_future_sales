The following steps were acknowledged, but unfortunately would breach the scope of this research project at the time being.

This includes simpler steps, like extending the zero sales from its current state, which only matches item and shop combinations on a given month, to the entire timespan.
This would inflate the current number of rows, approximately 11 million --- which are already now cumbersome to handle --- by 4 times.

Next, we would take a closer look at the final features and potentially drop features that are having a negative impact on the model's performance. For this, we would have to reevaluate the correlations between features to detect potential multicollinear values. Additionally, verifying the feature importance of individual features would be beneficial.

Then, we would aim for a more throughout evaluation of different modelling techniques such as decision trees or \acrshort{lstm}. Or applying different frameworks such as \texttt{xgboost} or \texttt{\acrshort{lgbm}}.
These predictions can then be utilized using ensemble learning in order to increase the performance even further. This will have to be postponed for the time being.
