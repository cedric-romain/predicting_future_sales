Dealing with the numerous challenges of handling large datasets along the road of this project has been incredibly frustrating at times. In the end, sticking to the goal and overcoming these obstacles has been immensely rewarding.

The most notable takeaways from the project were the importance of an \acrshort{eda}, how to craft new meaningful features in a time series problem and the impact of various regularization techniques.

The \acrshort{eda} was a perfect showcase of the impact of gaining domain knowledge on a given problem. Understanding how the records of the outliers came about and spotting the train data which is irrelevant towards the test data. 
These all lead to solid increases in performance.

New concepts like lag features were discovered an opened up a realm of possibilities when working with time series in the future. These were of particular importance when real world data brought previously unknown items into the mix.

Last but not least, we learned a lot when applying various regularization models, which surprisingly revealed that \gls{hyperparameter} tuning does not always imply improvements in performance.
